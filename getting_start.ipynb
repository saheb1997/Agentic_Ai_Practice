{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c2cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55d18bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3fbcfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aec3a773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x1083a3700> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1083a2aa0> root_client=<openai.OpenAI object at 0x1083a38e0> root_async_client=<openai.AsyncOpenAI object at 0x1083a34f0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96764e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a category of artificial intelligence that is designed to create new content, including text, images, audio, and video. These AI systems are typically based on advanced machine learning models, particularly neural networks, which have been trained on vast datasets to learn patterns and structures that enable them to generate outputs that resemble human-created content.\\n\\nKey characteristics of generative AI include:\\n\\n1. **Content Creation**: Generative AI can produce novel content rather than merely analyzing or categorizing existing data. This makes it applicable in various fields such as art, music, design, writing, and even software development.\\n\\n2. **Models Used**: Common generative models include Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer-based models like GPT (Generative Pre-trained Transformer).\\n\\n3. **Applications**: \\n   - **Text Generation**: Tools like GPT-3 or ChatGPT can generate coherent text for applications in writing assistance, chatbots, and content generation.\\n   - **Image and Video Creation**: Models like DALL-E and Midjourney create original images from textual descriptions, while GANs can generate realistic images and even animations.\\n   - **Music and Audio**: AI can compose music, create sound effects, or even generate voices.\\n\\n4. **Ethical and Practical Considerations**: The use of generative AI raises several ethical issues, including concerns about plagiarism, misinformation, deepfakes, and the potential for bias. As it becomes more powerful, ensuring responsible use is a key challenge.\\n\\nOverall, generative AI represents a significant frontier in machine learning, enabling machines to mimic human creativity and expand the possibilities of what computers can create.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 345, 'prompt_tokens': 12, 'total_tokens': 357, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-Bvec50hngVLJlFvFfqQKtIskMzNAw', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--2cb85634-dd63-4edc-b135-3d75c70a85e3-0' usage_metadata={'input_tokens': 12, 'output_tokens': 345, 'total_tokens': 357, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Input and get response from llm\n",
    "result = llm.invoke(\"What is generative AI\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37b59935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are an expert AI Engineer. Provided me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are an expert AI Engineer. Provided me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "    \n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4fce5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangSmith is a product developed by LangChain, designed to streamline and enhance the development process for applications utilizing large language models (LLMs). It provides a unified platform for testing, evaluating, debugging, and monitoring LLM applications. Key features include:\\n\\n1. **Dev Tools**: LangSmith offers developer tools that allow for rapid debugging and testing of language models, facilitating a more efficient development cycle.\\n\\n2. **Testing Framework**: It includes a framework for testing LLM outputs against expected outcomes, helping developers ensure model reliability and performance.\\n\\n3. **Evaluation Metrics**: The platform provides metrics for evaluating the quality and accuracy of LLM-generated content, enabling better assessment and iteration.\\n\\n4. **Monitoring and Analytics**: LangSmith incorporates features for real-time monitoring and analytics, providing insights into how models perform in production.\\n\\nOverall, LangSmith aims to simplify the complex workflows involved in building and maintaining robust language model applications, making it an attractive tool for AI engineers and developers working with LLMs.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 201, 'prompt_tokens': 33, 'total_tokens': 234, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BvgcJUrtH1qKZvuv96L0cwdKZuUnp', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--5cdeab77-1a99-4c81-8663-ed0a496571a4-0' usage_metadata={'input_tokens': 33, 'output_tokens': 201, 'total_tokens': 234, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt| llm \n",
    "response=chain.invoke({\"input\":\"can you tell me about langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5962c134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1621456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm |output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52fe5ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Langsmith is a tool developed by LangChain, designed to improve the development process for language model applications. It enables developers to run detailed evaluations of language models, integrating seamlessly with the LangChain framework. \n",
      "\n",
      "With Langsmith, you can:\n",
      "\n",
      "1. **Track Performance:** It helps in tracking how well your language models perform across various datasets and tasks, making it easier to understand their efficacy and areas for improvement.\n",
      "\n",
      "2. **Data Management:** Langsmith offers robust capabilities for managing the datasets used to train and evaluate models, ensuring that you can maintain high data quality and consistency.\n",
      "\n",
      "3. **Experimentation:** It encourages experimentation by allowing you to easily configure and run different model configurations, track changes, and compare results.\n",
      "\n",
      "4. **Debugging and Iteration:** Langsmith facilitates debugging and iteration by providing in-depth logging and visualization, making it easier to pinpoint issues and refine models iteratively.\n",
      "\n",
      "This tool is particularly useful for AI engineers and developers focusing on NLP tasks, as it bridges gaps between initial prototyping and production-ready deployments by providing insights and clarity into model behavior.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
